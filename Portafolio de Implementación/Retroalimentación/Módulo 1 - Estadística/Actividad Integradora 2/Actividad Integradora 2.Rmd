---
title: "Actividad Integradora 2"
author: "Héctor Hibran Tapia Fernández - A01661114"
date: "2024-09-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Actividad Integradora 2

Una empresa automovilística china aspira a entrar en el mercado estadounidense. Desea establecer allí una unidad de fabricación y producir automóviles localmente para competir con sus contrapartes estadounidenses y europeas. Contrataron una empresa de consultoría de automóviles para identificar los principales factores de los que depende el precio de los automóviles, específicamente, en el mercado estadounidense, ya que pueden ser muy diferentes del mercado chino. Esencialmente, la empresa quiere saber:

 - Qué variables son significativas para predecir el precio de un automóvil
 - Qué tan bien describen esas variables el precio de un automóvil
 
Con base en varias encuestas de mercado, la consultora ha recopilado un gran conjunto de datos de diferentes tipos de automóviles en el mercado estadounidense que presenta en el siguiente archivo "Download" archivo. Las variables recopiladas vienen descritas en el diccionario de términos "diccionario de términos". Por un análisis de correlación, la empresa automovilistica tiene interés en analizar las variables agrupadas de la siguiente forma para hacer el análisis de variables significativas:

1. **Primer grupo.** Distancia entre los ejes (wheelbase), tipo de gasolina que usa y caballos de fuerza
2. **Segundo grupo.** Altura del auto, ancho del auto y si es convertible o no.
3. **Tercer grupo.** Tamaño del motor (ensinesize), carrera o lanzamiento del pistón (stroke) y localización del motor en el carro

Selecciona uno de los tres grupos analizados (te será asignado por tu profesora) y analiza la significancia de las variables para predecir o influir en la variable precio. ¿propondrías una nueva agrupación a la empresa automovilísitica?


## I. Exploración de la base de datos

### 1. Exploración de la base de datos

-> Calcula medidas estadísticas apropiadas para las variables:

- cuantitativas (media, desviación estándar, cuantiles, etc)

```{r}
df = read.csv("./precios_autos.csv")
df_tercer_grupo = df[, c("enginetype", "enginelocation", "stroke", "price")]

library(psych)
describe(df_tercer_grupo)
summary(df_tercer_grupo)
```

- cualitativas: cuantiles, frecuencias (puedes usar el comando table o prop.table)

```{r}
df_cualitativas = df_tercer_grupo[sapply(df_tercer_grupo, is.factor) | sapply(df_tercer_grupo, is.character)]

lapply(df_cualitativas, function(col) {cat("\nVariable:", colnames(as.data.frame(col)), "\n")
  print(table(col)) # absolutas
  print(prop.table(table(col))) # relativas
})
```

-> Analiza la correlación entre las variables (analiza posible colinealidad entre las variables)

```{r}
df_cuantitativas = df_tercer_grupo[sapply(df_tercer_grupo, is.numeric)]
matriz_correlacion = cor(df_cuantitativas)
matriz_correlacion
```

Hay colinealidad positiva muy baja entra las variables numéricas.

-> Explora los datos usando herramientas de visualización (si lo consideras necesario):

- Variables cuantitativas: Boxplot (visualización de datos atípicos), Histogramas, Diagramas de dispersión y correlación por pares.

```{r}
for (col_name in colnames(df_cuantitativas)) {boxplot(df_cuantitativas[[col_name]], main = paste("Boxplot de", col_name), col = "lightblue", outline = TRUE)}
```

```{r}
for (col_name in colnames(df_cuantitativas)) {hist(df_cuantitativas[[col_name]], main = paste("Histograma de", col_name),xlab = col_name, col = "gray", border = "black")}
```

```{r}
plot(df_cuantitativas$stroke, df_cuantitativas$price, main = "Diagrama de Dispersión: stroke vs price", xlab = "stroke", ylab = "price", pch = 19, col = "darkgray")
```

```{r}
library(GGally)
ggpairs(df_cuantitativas, title = "Correlación por Pares")
```


- Variables categóricas: Distribución de los datos (diagramas de barras, diagramas de pastel) y Boxplot por categoría de las variables cuantitativas

```{r}
for (col_name in colnames(df_cualitativas)) {barplot(table(df_cualitativas[[col_name]]), main = paste("Histograma de", col_name),xlab = col_name, col = "gray", border = "black")}
```

```{r}
for (col_name in colnames(df_cualitativas)) {pie(table(df_cualitativas[[col_name]]), main = paste("Diagrama de Pastel de", col_name),col = rainbow(length(table(df_cualitativas[[col_name]]))))}
```

```{r}
for (quant_col in colnames(df_cuantitativas)) {boxplot(df_cuantitativas[[quant_col]] ~ df_cualitativas[["enginetype"]], main = paste("Boxplot de", quant_col, "por enginetype"),xlab = "enginetype", ylab = quant_col, col = "lightblue")}

for (quant_col in colnames(df_cuantitativas)) {boxplot(df_cuantitativas[[quant_col]] ~ df_cualitativas[["enginelocation"]],
main = paste("Boxplot de", quant_col, "por enginelocation"),xlab = "enginelocation", ylab = quant_col, col = "lightblue")}
```

## Modelación y verificación del modelo

### 1. Encuentra la ecuación de regresión de mejor ajuste. Propón al menos 2 modelos de ajuste para encontrar la mejor forma de ajustar la variable precio.

```{r}
modelo1 = lm(price ~ enginetype + enginelocation + stroke, data = df_tercer_grupo)
M1 = summary(modelo1)
M1
```

```{r}
modelo2 = lm(price ~ enginetype * enginelocation * stroke, data = df_tercer_grupo)
M2 = summary(modelo2)
M2
```

### 2. Para cada uno de los modelos propuestos:

-> Realiza la regresión entre las variables involucradas. LISTO, SE HIZO ARRIBA.

-> Analiza la significancia del modelo:

- Valida la significancia del modelo con un alfa de 0.04 (incluye las hipótesis que pruebas y el valor frontera)

```{r}
p_valor_modelo1 = M1$coefficients[1, 4]
p_valor_modelo2 = M2$coefficients[1, 4]

if (p_valor_modelo1 < 0.04) {
    cat("Se rechaza la hipótesis nula (H0) para el modelo 1. Hay evidencia suficiente para afirmar que existe una relación lineal significativa.\n")
} else {
    cat("No se rechaza la hipótesis nula (H0) para el modelo 1. No hay evidencia suficiente para afirmar que existe una relación lineal significativa.\n")
}

if (p_valor_modelo2 < 0.04) {
    cat("Se rechaza la hipótesis nula (H0) para el modelo 2. Hay evidencia suficiente para afirmar que existe una relación lineal significativa.\n")
} else {
    cat("No se rechaza la hipótesis nula (H0) para el modelo 2. No hay evidencia suficiente para afirmar que existe una relación lineal significativa.\n")
}
```

- Valida la significancia de β̂i con un alfa de 0.04 (incluye las hipótesis que pruebas y el valor frontera de cada una de ellas)

```{r}
for (i in 1:length(p_valor_modelo1)) {
  if (p_valor_modelo1[i] < 0.04) {
    cat("Se rechaza la hipótesis nula (H0) para el coeficiente β̂", i, " en el modelo 1. Hay evidencia suficiente para afirmar que el coeficiente es significativo.\n")
  } else {
    cat("No se rechaza la hipótesis nula (H0) para el coeficiente β̂", i, " en el modelo 1. No hay evidencia suficiente para afirmar que el coeficiente es significativo.\n")
  }
}

for (i in 1:length(p_valor_modelo2)) {
  if (p_valor_modelo2[i] < 0.04) {
    cat("Se rechaza la hipótesis nula (H0) para el coeficiente β̂", i, " en el modelo 2. Hay evidencia suficiente para afirmar que el coeficiente es significativo.\n")
  } else {
    cat("No se rechaza la hipótesis nula (H0) para el coeficiente β̂", i, " en el modelo 2. No hay evidencia suficiente para afirmar que el coeficiente es significativo.\n")
  }
}
```

- Indica cuál es el porcentaje de variación explicada por el modelo.

```{r}
R2_modelo1 <- M1$r.squared
R2_modelo2 <- M2$r.squared

cat("El porcentaje de variación explicada por el modelo 1 es: ", R2_modelo1 * 100, "%\n")
cat("El porcentaje de variación explicada por el modelo 2 es: ", R2_modelo2 * 100, "%\n")
```

- Dibuja el diagrama de dispersión de los datos por pares y la recta de mejor ajuste.

```{r}
library(ggplot2)
library(ggpubr)

p1 = ggplot(df_tercer_grupo, aes(x = stroke, y = price)) + geom_point() + geom_smooth(method = "lm", se = FALSE, color = "blue") + labs(title = "Stroke vs Price", x = "Stroke", y = "Price")
ggarrange(p1, ncol = 1, nrow = 1)
```


```{r}
p2 = ggplot(df_tercer_grupo, aes(x = stroke, y = price, color = enginetype)) + geom_point() + geom_smooth(method = "lm", se = FALSE) + labs(title = "Enginetype vs Price", x = "Enginetype", y = "Price") + theme_minimal()  
print(p2)
```

```{r}
p3 = ggplot(df_tercer_grupo, aes(x = stroke, y = price, color = enginelocation)) + geom_point() + geom_smooth(method = "lm", se = FALSE) + labs(title = "Enginelocation vs Price", x = "Enginelocation", y = "Price") + theme_minimal() 
print(p3)
```

### 3. Analiza la validez de los modelos propuestos:

-> Normalidad de los residuos

```{r}
library(nortest)
ad.test(M1$residuals)
ad.test(M2$residuals)

par(mfrow = c(1,2))
qqnorm(M1$residuals, main = "Q-Q Plot - Modelo1")
qqline(M1$residuals)
hist(M1$residuals, freq = FALSE, main = "M1", xlab = "Residuals", ylab = "Density")
lines(density(M1$residuals), col = "red")
curve(dnorm(x, mean = mean(M1$residuals), sd=sd(M1$residuals)), add = TRUE, col = "blue", lwd = 2)
par(mfrow = c(1,1))

par(mfrow = c(1,2))
qqnorm(M2$residuals, main = "Q-Q Plot - Modelo2")
qqline(M2$residuals)
hist(M2$residuals, freq = FALSE, main = "M2", xlab = "Residuals", ylab = "Density")
lines(density(M2$residuals), col = "red")
curve(dnorm(x, mean = mean(M2$residuals), sd=sd(M2$residuals)), add = TRUE, col = "blue", lwd = 2)
par(mfrow = c(1,2))
```
Se muestran los QQplots de cada modelo donde medimos y comparamos como se comportan los datos, comparandolos con los de una distribución normal, el desvío de datos muestra la diferencia que se tiene versus una normal, tamboén se puede hacer otro tipo de comparaciones con otrs distribuciones pero la normal es la más usada.

De esta forma podemos verificar la linealidad de los datos, y pordemos confirmar que no se comportan completamente como una normal.

-> Verificación de media cero

```{r}
t.test(M1$residuals)
```

- El valor estadístico t: 2.7897e-15, es increíblemente pequeño, muy cercano a 0. Indica diferencia entre la media de los residuales y 0. (La diferencia en este caso en casi nula)
- Df: Se refiere a los grados de libertad: # Datos - # Parámetros
- P-Value: 1, es demasiado alto indica lo que nos dice que no hay evidencia suficiente para rechazar la hipótesis nula de que la media de los residuales es igual a 0. (Por cierto esta es la H0)
- 95 percent confidence interval: Estamos 95% seguros de que la media de los residuales está dentro de este (-877.9708  877.9708) rango.
- Media de los residuales: Es prácticamente 0.



```{r}
t.test(M2$residuals)
```

- El valor estadístico t: 9.8234e-16, es increíblemente pequeño, muy cercano a 0. Indica diferencia entre la media de los residuales y 0. (La diferencia en este caso en casi nula)
- Df: Se refiere a los grados de libertad: # Datos - # Parámetros
- P-Value: 1, es demasiado alto indica lo que nos dice que no hay evidencia suficiente para rechazar la hipótesis nula de que la media de los residuales es igual a 0. (Por cierto esta es la H0)
- 95 percent confidence interval: Estamos 95% seguros de que la media de los residuales está dentro de este (-854.8474  854.8474) rango.
- Media de los residuales: Es prácticamente 0.


-> Homocedasticidad, linealidad e independencia

```{r}
plot(modelo1$fitted.values, modelo1$residuals, main = "Modelo1", xlab = "Valores Ajustados", ylab = "Residuos")
abline(h = 0, col = "blue")

plot(modelo2$fitted.values, modelo2$residuals, main = "Modelo2", xlab = "Valores Ajustados", ylab = "Residuos")
abline(h = 0, col = "blue")
```

-> Interpreta cada uno de los analisis que realizaste

Modelo 1: Este modelo es una regresión lineal cada variable que está en este modelo afecta de manera independiente y lineal, NO se tiene intereacción entre ellas, lo que significa que cada variable tiene su coeficiente que describe el efecto que se tiene sobre la variable predictora "price".

Por otro lado el Modelo 2, cada variable tiene interacciones entre ellas, lo que significa que además de tener en cuenta el efecto directo de cada variable en el precio, también se tiene el efecto de cada como cada una variables depende de los valores de las otras.

Para ambos modelos podemos decir que los datos se ajustan bien en términos de los residuales.

### 4. Emite una conclusión final sobre el mejor modelo de regresión lineal y contesta la pregunta central:

-> Concluye sobre el mejor modelo que encontraste y argumenta por qué es el mejor.

- Creo que el mejor modelo es el Modelo 1 debido a que es más simple además en la comparación de sus R2s no es tán grande la diferencia como se espera de un modelo más complejo y completo como el Modelo 2, para el Modelo 2 hay muchas interacciones que no son significativas, o que de plano en el summary se muestran como NA. Comparando los Errores Estándar se muestra lo mismo, el Modelo 2 tiene un ES ligeramente menor pero la complejidad del modelo 2 no se compara con la simplicidad del modelo 1, por estás razones considero que el modelo 1 es mejor.

-> ¿Cuáles de las variables asignadas influyen en el precio del auto? ¿de qué manera lo hacen?

```{r}
boxplot(price ~ enginetype, data = df_tercer_grupo, main = "Precio del Auto por Tipo de Motor", ylab = "Precio del Auto", xlab = "Tipo de Motor", col = "lightblue")

boxplot(price ~ enginelocation, data = df_tercer_grupo, main = "Precio del Auto por Ubicación del Motor", ylab = "Precio del Auto", xlab = "Ubicación del Motor", col = "lightblue")
```

```{r}
M1 = summary(modelo1)
M1
```

Tomando en cuenta lo anterior las variables que son estadísticamente significativas en el modelo, son las que tienen un valor p menor a 0.05, lo que influencia en el precio del auto.

- enginetypedohcv
- enginetypeohc
- enginetypeohcf
- enginetypeohcv
- enginelocationrear
- stroke

## III. Intervalos de predicción y confianza

### 1. Con los datos de las variables asignadas construye la gráfica de los intervalos de confianza y predicción para la estimación y predicción del precio para el mejor modelo seleccionado:

-> Calcula los intervalos para la variable Y

```{r}
modelo_stroke <- lm(price ~ stroke, data = df_tercer_grupo)
data_numerica = data.frame(stroke = df_tercer_grupo$stroke)
predicciones = predict(modelo_stroke, newdata = data_numerica, interval = "confidence")

df_tercer_grupo$fit = predicciones[, "fit"]
df_tercer_grupo$lwr = predicciones[, "lwr"]
df_tercer_grupo$upr = predicciones[, "upr"]

p1 = ggplot(df_tercer_grupo, aes(x = stroke, y = price)) + geom_point() + geom_line(aes(y = lwr), color = "red", linetype = "dashed") +  geom_line(aes(y = upr), color = "red", linetype = "dashed") + geom_smooth(method = "lm", formula = y ~ x, se = TRUE, level = 0.97, col = "blue", fill = "pink2") + theme_light() + labs(title = "Relación entre Stroke y Precio del Auto", x = "Stroke", y = "Price")
ggarrange(p1, ncol = 1, nrow = 1)
```

-> Selecciona la categoría de la variable cualitativa que, de acuerdo a tu análisis resulte la más importante, y separa la base de datos por esa variable categórica.

```{r}
df_motor_trasero = subset(df_tercer_grupo, enginelocation == "rear")
df_motor_delantero = subset(df_tercer_grupo, enginelocation == "front")
```

-> Grafica por pares de variables numéricas

```{r}
modelo_stroke_enginetype = lm(price ~ stroke * enginetype, data = df_tercer_grupo)
data_categorica = data.frame(stroke = df_tercer_grupo$stroke, enginetype = df_tercer_grupo$enginetype)
predicciones = predict(modelo_stroke_enginetype, newdata = data_categorica, interval = "confidence")

df_tercer_grupo$fit = predicciones[, "fit"]
df_tercer_grupo$lwr = predicciones[, "lwr"]
df_tercer_grupo$upr = predicciones[, "upr"]

p2 <- ggplot(df_tercer_grupo, aes(x = stroke, y = price, color = enginetype)) + geom_point() + geom_line(aes(y = lwr, color = enginetype), linetype = "dashed") + geom_line(aes(y = upr, color = enginetype), linetype = "dashed") + geom_smooth(method = "lm", formula = y ~ x, se = TRUE, level = 0.97) + theme_minimal() + labs(title = "Stroke vs Price por Enginetype", x = "Stroke", y = "Price")

print(p2)
```

### 2. Puedes hacer el mismo análisis para otra categoría de la variable cualitativa, pero no es necesario, bastará con que justiques la categoría seleccionada anteriormente.

Se eligió esa categoría porque es la que es estadísticamente más significativa.

## IV. Más allá:

-> Contesta la pregunta referida a la agrupación de variables que propuso la empresa para el análisis: ¿propondrías una nueva agrupación de las variables a la empresa automovilísitica?

```{r}
datos = read.csv("./precios_autos.csv")
colnames(datos)
```

Teniendo en cuenta todas esas variables, definitivamente no me iría directamente a lo que tiene sentido lógico o empírco armar los grupos, me iría por un análisis de mercado o análisis estadístico que me ayude a agrupar las 

-> Retoma todas las variables y haz un análisis estadístico muy leve (medias y correlación) de cómo crees que se deberían agrupar para analizarlas.

```{r}
library(readr)
library(dplyr)

numericas <- datos %>%select(where(is.numeric))
correlacion <- cor(numericas, use = "complete.obs")
print(correlacion)
```

Con esto armaría:

Grupo con el tamaño y peso del vehículo:
wheelbase, carlength, carwidth, curbweight

Grupo con el motor y rendimiento:
enginesize, horsepower, curbweight, price

Grupo con el consumo de combustible:
citympg, highwaympg, horsepower




